import polars as pl
import os
import time

def process_data_lazy():
    print("B·∫Øt ƒë·∫ßu quy tr√¨nh (Ch·∫ø ƒë·ªô Lazy - Ti·∫øt ki·ªám RAM)...")
    start_time = time.time()

    # --- 1. KI·ªÇM TRA FILE ---
    if not os.path.exists("dataset_ohlcv.parquet") or not os.path.exists("dataset_assets.parquet"):
        print("L·ªói: Thi·∫øu file ngu·ªìn. H√£y ch·∫°y l·∫°i export_data.py.")
        return

    try:
        # --- 2. S·ª¨ D·ª§NG SCAN (LAZY LOADING) ---
        # scan_parquet thay v√¨ read_parquet -> Kh√¥ng t·ªën RAM ngay l·∫≠p t·ª©c
        print("   -> ƒêang qu√©t d·ªØ li·ªáu (Lazy Scan)...")
        lf_prices = pl.scan_parquet("dataset_ohlcv.parquet")
        lf_assets = pl.scan_parquet("dataset_assets.parquet")

        # Chu·∫©n b·ªã b·∫£ng Assets
        lf_assets_clean = lf_assets.select([
            pl.col("id").alias("asset_id"), 
            "symbol", 
            "asset_type", 
            "exchange"
        ])

        # Join (Lazy)
        lf_final = lf_prices.join(lf_assets_clean, on="asset_id", how="left")
        
        # S·∫Øp x·∫øp (B·∫Øt bu·ªôc cho Time-series)
        lf_final = lf_final.sort(["symbol", "ts"])

        # --- 3. FEATURE ENGINEERING (LAZY) ---
        print("   -> ƒêang l·∫≠p k·∫ø ho·∫°ch t√≠nh to√°n (Plan)...")
        
        LAG_DAYS = 5 

        # T√≠nh to√°n c√°c c·ªôt (Logic v·∫´n gi·ªØ nguy√™n nh∆∞ng d√πng Lazy Frame)
        lf_final = lf_final.with_columns([
            # Forward Fill ƒë·ªÉ l·∫•p l·ªó h·ªïng d·ªØ li·ªáu
            pl.col("close").forward_fill().over("symbol"),
            pl.col("volume").forward_fill().over("symbol"),
            pl.col("open").forward_fill().over("symbol"),
            pl.col("high").forward_fill().over("symbol"),
            pl.col("low").forward_fill().over("symbol"),
        ]).with_columns([
            # Target: Log Return
            (pl.col("close").log().diff().over("symbol").fill_null(0.0)).alias("log_return"),
            # Feature: Log Range
            (pl.col("high").log() - pl.col("low").log()).fill_null(0.0).alias("log_range"),
            # Feature: Log Volume Change
            (pl.col("volume").log1p().diff().over("symbol").fill_null(0.0)).alias("vol_change_log"),
             # Feature: Relative Volume (S·ª≠a min_periods -> min_samples)
            (pl.col("volume") / pl.col("volume").rolling_mean(window_size=20, min_samples=1).over("symbol"))
            .fill_nan(1.0).fill_null(1.0).alias("vol_relative")
        ])

        # T·∫°o Lagged Features
        # L∆∞u √Ω: Vi·∫øt v√≤ng l·∫∑p trong Lazy h∆°i kh√°c m·ªôt ch√∫t, ta d√πng list comprehension
        lagged_exprs = [
            pl.col("log_return").shift(i).over("symbol").alias(f"lag_return_{i}")
            for i in range(1, LAG_DAYS + 1)
        ]
        lf_final = lf_final.with_columns(lagged_exprs)

        # --- 4. L·ªåC V√Ä L√ÄM S·∫†CH ---
        # S·ª≠a l·ªói Warning: D√πng .len() thay v√¨ .count()
        # T√≠nh ƒë·ªô d√†i chu·ªói d·ªØ li·ªáu cho m·ªói m√£ ƒë·ªÉ l·ªçc r√°c
        # Ta c·∫ßn th·ª±c hi·ªán b∆∞·ªõc n√†y t√°ch bi·ªát m·ªôt ch√∫t v√¨ Lazy kh√≥ join v·ªõi ch√≠nh n√≥ sau khi group
        
        # ƒê·ªÉ an to√†n v√† ch·∫Øc ch·∫Øn ch·∫°y ƒë∆∞·ª£c, ta s·∫Ω COLLECT (Load v√†o RAM) ·ªü b∆∞·ªõc n√†y
        # V√¨ sau khi l·ªçc b·ªõt d·ªØ li·ªáu r√°c, RAM s·∫Ω ch·ªãu t·∫£i ƒë∆∞·ª£c.
        print("   -> ƒêang th·ª±c thi t√≠nh to√°n v√† load v√†o RAM (B∆∞·ªõc n√†y m·∫•t kho·∫£ng 30s-1p)...")
        df_final = lf_final.collect() 

        print(f"   -> ƒê√£ load v√†o RAM: {len(df_final)} d√≤ng. ƒêang l·ªçc m√£ r√°c...")

        # --- 5. L·ªåC M√É R√ÅC (EAGER MODE - CH·∫†Y TR√äN RAM) ---
        # S·ª≠a l·ªói crash c≈© t·∫°i ƒë√¢y: D√πng .len() v√† c·ªôt "len"
        symbol_counts = df_final.group_by("symbol").len() # T·∫°o ra c·ªôt "symbol" v√† "len"
        
        # L·∫•y danh s√°ch m√£ h·ª£p l·ªá (> 60 ng√†y)
        valid_symbols = symbol_counts.filter(pl.col("len") > 60).select("symbol")
        
        # Filter d·ªØ li·ªáu ch√≠nh
        df_final = df_final.join(valid_symbols, on="symbol", how="inner")

        # L√†m s·∫°ch NaN l·∫ßn cu·ªëi
        df_final = df_final.filter(
            ~pl.col("log_return").is_infinite() & 
            ~pl.col("vol_change_log").is_infinite()
        ).drop_nulls(subset=["log_return", "lag_return_5"])

        # Encode (Chuy·ªÉn ch·ªØ sang s·ªë)
        df_final = df_final.with_columns([
            pl.col("asset_type").cast(pl.Categorical).to_physical().alias("type_encoded"),
            pl.col("exchange").cast(pl.Categorical).to_physical().alias("exchange_encoded"),
            pl.col("symbol").cast(pl.Categorical).to_physical().alias("symbol_encoded")
        ])

        # --- 6. L∆ØU FILE ---
        output_file = "dataset_ml_ready.parquet"
        print(f"üíæ ƒêang l∆∞u file '{output_file}'...")
        df_final.write_parquet(output_file)
        
        print(f"‚úÖ TH√ÄNH C√îNG! T·ªïng th·ªùi gian: {time.time() - start_time:.2f}s")
        print(f"   S·ªë d√≤ng d·ªØ li·ªáu s·∫°ch: {len(df_final)}")

    except Exception as e:
        print("\n‚ùå C√ì L·ªñI X·∫¢Y RA:")
        print(e)
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    process_data_lazy()