{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd62adb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 1. SETUP & CONFIGURATION\n",
    "# ==============================================================================\n",
    "# C√†i ƒë·∫∑t th∆∞ vi·ªán (Ch·ªâ ch·∫°y l·∫ßn ƒë·∫ßu)\n",
    "# !pip install pytorch-forecasting pytorch-lightning polars --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Pytorch Forecasting\n",
    "from pytorch_forecasting import TimeSeriesDataSet, TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "# Thi·∫øt l·∫≠p Random Seed ƒë·ªÉ t√°i t·∫°o k·∫øt qu·∫£\n",
    "SEED = 42\n",
    "seed_everything(SEED, workers=True)\n",
    "\n",
    "# C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n\n",
    "DATA_PATH = \"/kaggle/input/financial-data-ohlcv-global/dataset_final_kaggle.parquet\"\n",
    "CHECKPOINT_PATH = \"/kaggle/working/tft_v1\"\n",
    "\n",
    "# Tham s·ªë m√¥ h√¨nh\n",
    "MAX_ENCODER_LENGTH = 30 # Nh√¨n l·∫°i 30 ng√†y qu√° kh·ª©\n",
    "MAX_PREDICTION_LENGTH = 5 # D·ª± b√°o 5 ng√†y t∆∞∆°ng lai\n",
    "BATCH_SIZE = 128\n",
    "MAX_EPOCHS = 50 \n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1567c55",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 2. LOAD DATA & PREPROCESSING\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"1. ƒêang t·∫£i v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu...\")\n",
    "df_pl = pl.read_parquet(DATA_PATH)\n",
    "df = df_pl.to_pandas()\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi v√† l√†m s·∫°ch cu·ªëi c√πng (ƒê·∫£m b·∫£o ƒë√∫ng type cho Pytorch)\n",
    "df = df.sort_values(by=['symbol', 'ts']).reset_index(drop=True)\n",
    "df['symbol_id'] = df['symbol'].astype('category').cat.codes\n",
    "df['asset_type'] = df['asset_type'].astype('category').cat.codes\n",
    "\n",
    "# Lo·∫°i b·ªè c√°c m√£ √≠t d·ªØ li·ªáu (D∆∞·ªõi 1 nƒÉm, ƒë·ªÉ tƒÉng ch·∫•t l∆∞·ª£ng)\n",
    "symbols_to_keep = df.groupby('symbol').size().nlargest(3000).index # Gi·ªØ 3000 m√£ t·ªët nh·∫•t\n",
    "df = df[df['symbol'].isin(symbols_to_keep)].copy()\n",
    "\n",
    "print(f\"   -> K√≠ch th∆∞·ªõc t·∫≠p d·ªØ li·ªáu cu·ªëi c√πng: {df.shape[0]:,} d√≤ng ({len(symbols_to_keep)} m√£)\")\n",
    "\n",
    "# Chia t·∫≠p Train/Validation theo TH·ªúI GIAN\n",
    "# Gi·ªØ 5 ng√†y d·ª± b√°o + 10 ng√†y cho Encoder (t·ªïng 15 ng√†y) ƒë·ªÉ ƒë√°nh gi√°.\n",
    "training_cutoff = df[\"time_idx\"].max() - MAX_PREDICTION_LENGTH * 3 \n",
    "print(f\"   -> C·∫Øt d·ªØ li·ªáu t·∫°i time_idx: {training_cutoff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bd7dc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 3. ƒê·ªäNH NGHƒ®A TIMESERIESDATASET\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"2. ƒêang c·∫•u h√¨nh TimeSeriesDataSet...\")\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    df[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"log_return\", # M·ª•c ti√™u: D·ª± b√°o l·ª£i nhu·∫≠n\n",
    "    group_ids=[\"symbol_id\"], # Nh√≥m: Multi-asset learning\n",
    "    \n",
    "    max_encoder_length=MAX_ENCODER_LENGTH,\n",
    "    max_prediction_length=MAX_PREDICTION_LENGTH,\n",
    "    \n",
    "    # 3a. STATIC (C·ªë ƒë·ªãnh):\n",
    "    static_categoricals=[\"symbol_id\", \"asset_type\"],\n",
    "    \n",
    "    # 3b. KNOWN REAL (Bi·∫øt tr∆∞·ªõc t∆∞∆°ng lai):\n",
    "    time_varying_known_reals=[\n",
    "        \"time_idx\", \"day_sin\", \"day_cos\", \"month_sin\", \"month_cos\"\n",
    "    ],\n",
    "    \n",
    "    # 3c. UNKNOWN REAL (Quan s√°t qu√° kh·ª©):\n",
    "    time_varying_unknown_reals=[\n",
    "        \"log_return\", \"vol_relative\", \"bb_width\", \"roc_10\", \"macd_proxy\", # Indicators\n",
    "        \"ctx_sp500_ret\", \"ctx_gold_ret\", \"ctx_oil_ret\", \"ctx_forex_ret\",  # Global Context\n",
    "        \"ctx_sp500_vol\", \"ctx_gold_vol\", \"ctx_oil_vol\", \"ctx_forex_vol\",  # Global Volume\n",
    "    ],\n",
    "    \n",
    "    # Chu·∫©n h√≥a ri√™ng cho t·ª´ng m√£\n",
    "    target_normalizer=GroupNormalizer(groups=[\"symbol_id\"], center=False, scale_by_group=True),\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")\n",
    "\n",
    "# T·∫°o Validation Dataset\n",
    "validation = TimeSeriesDataSet.from_dataset(training, df, min_prediction_idx=training_cutoff + 1, overwrite_existing_dataset_fields=True)\n",
    "\n",
    "# T·∫°o DataLoaders (TƒÉng t·ªëc ƒë·ªçc d·ªØ li·ªáu)\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=BATCH_SIZE, num_workers=4)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=BATCH_SIZE, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c75e9bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 4. KH·ªûI T·∫†O V√Ä HU·∫§N LUY·ªÜN MODEL TFT\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"3. ƒêang c·∫•u h√¨nh TFT Model v√† Callbacks...\")\n",
    "\n",
    "# Callbacks:\n",
    "# 1. Early Stopping: D·ª´ng n·∫øu val_loss kh√¥ng c·∫£i thi·ªán trong 7 epochs\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=7, verbose=False, mode=\"min\")\n",
    "# 2. Model Checkpoint: L∆∞u model t·ªët nh·∫•t (val_loss th·∫•p nh·∫•t)\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"val_loss\",\n",
    "    dirpath=CHECKPOINT_PATH,\n",
    "    filename=\"best_tft_v1-{epoch:02d}-{val_loss:.4f}\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Kh·ªüi t·∫°o TFT Model\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    hidden_size=64,\n",
    "    attention_head_size=4,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=64,\n",
    "    output_size=7, # 7 Quantiles cho QuantileLoss\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    optimizer=\"adam\",\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "# Kh·ªüi t·∫°o Trainer\n",
    "trainer = Trainer(\n",
    "    max_epochs=MAX_EPOCHS,\n",
    "    accelerator=\"gpu\",\n",
    "    devices=1,\n",
    "    gradient_clip_val=0.1,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback, LearningRateMonitor()],\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ B·∫ÆT ƒê·∫¶U TRAINING BASE TFT (Version 1.0)...\")\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")\n",
    "\n",
    "# L∆∞u Model cu·ªëi c√πng (N·∫øu kh√¥ng mu·ªën d√πng checkpoint)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)\n",
    "print(f\"‚úÖ Training ho√†n th√†nh! Model t·ªët nh·∫•t ƒë∆∞·ª£c l∆∞u t·∫°i: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2452eb2e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# 5. D·ª∞ B√ÅO & VISUALIZATION (Sau khi Training)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n4. ƒêang ki·ªÉm tra d·ª± b√°o tr√™n t·∫≠p Validation...\")\n",
    "\n",
    "# Ch·ªçn m·ªôt v√†i m√£ ng·∫´u nhi√™n ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì\n",
    "target_symbols = validation.data.symbol.unique()\n",
    "# Ch·ªçn 3 m√£ b·∫•t k·ª≥\n",
    "symbols_to_plot = np.random.choice(target_symbols, 3, replace=False)\n",
    "\n",
    "for sym in symbols_to_plot:\n",
    "    # L·ªçc d·ªØ li·ªáu c·ªßa m√£ ƒë√≥\n",
    "    encoder_data = df[lambda x: (x.symbol == sym) & (x.time_idx <= training_cutoff)]\n",
    "    last_encoder_data = encoder_data[encoder_data.time_idx == encoder_data.time_idx.max()]\n",
    "    \n",
    "    # L·∫•y d·ªØ li·ªáu validation cho m√£ ƒë√≥\n",
    "    validation_data = df[lambda x: (x.symbol == sym) & (x.time_idx > training_cutoff)]\n",
    "    \n",
    "    # D·ª± b√°o\n",
    "    raw_predictions = best_tft.predict(last_encoder_data, mode=\"raw\", return_x=True)\n",
    "    \n",
    "    # Plotting (s·ª≠ d·ª•ng th∆∞ vi·ªán n·ªôi b·ªô c·ªßa Pytorch Forecasting)\n",
    "    fig = best_tft.plot_prediction(\n",
    "        raw_predictions, \n",
    "        x=raw_predictions.x, \n",
    "        add_loss_to_title=True, \n",
    "        show_future_observed_values=True,\n",
    "        ax_kwargs={\"title\": f\"D·ª± b√°o 5 ng√†y cho M√£: {sym}\"}\n",
    "    )\n",
    "    fig.show() # Tr√™n Kaggle, b·∫°n s·∫Ω th·∫•y bi·ªÉu ƒë·ªì hi·ªÉn th·ªã ngay d∆∞·ªõi cell n√†y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27536b04",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
